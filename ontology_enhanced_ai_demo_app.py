import streamlit as st
import networkx as nx
import matplotlib.pyplot as plt
import json

# Load ontology data from file
try:
    with open("ontology_sample.json", "r") as f:
        ontology_data = json.load(f)
except FileNotFoundError:
    st.error("Ontology file (ontology_sample.json) not found. Please ensure it exists in the project directory.")
    ontology_data = {"concepts": [], "relations": []}
except json.decoder.JSONDecodeError as e:
    st.error(f"Invalid JSON in ontology_sample.json: {str(e)}. Please check the file for syntax errors (e.g., missing commas).")
    ontology_data = {"concepts": [], "relations": []}

# Page setup
st.set_page_config(page_title="OntoGuard-Inspired AI Demo", layout="wide")
st.title("ğŸ” OntoGuard-Inspired AI Demo")
st.subheader("Governance Layer Beneath LLMs: Real-Time Compliance & Reliability")

# Sidebar: Prompt-to-Ontology Mapping
st.sidebar.markdown("### ğŸ” Prompt-to-Ontology Mapping")
user_prompt = st.sidebar.text_input("Enter a user prompt:", placeholder="e.g., Is our sentiment model GDPR compliant?")

mapped_concepts = []
if user_prompt:
    if "hipaa" in user_prompt.lower():
        mapped_concepts = ["Compliance", "HIPAA", "Risk Assessment"]
    elif "gdpr" in user_prompt.lower():
        mapped_concepts = ["Compliance", "GDPR", "Policy Validation"]
    elif "trust" in user_prompt.lower():
        mapped_concepts = ["Trust Scoring", "Model Output"]

if mapped_concepts:
    st.sidebar.markdown("**Mapped Ontology Concepts:**")
    for concept in mapped_concepts:
        st.sidebar.markdown(f"- {concept}")

# Sidebar: White Paper and GitHub Links
st.sidebar.markdown("---")
st.sidebar.markdown("[ğŸ“„ View Public White Paper](https://github.com/MMM777-ai/ontoguard/blob/main/assets/Ontology-Enhanced%20AI%20-%20Public%20White%20Paper.pdf)")
st.sidebar.markdown("[ğŸŒ GitHub Repository](https://github.com/MMM777-ai/web-ontology-demo)")

# Prompt input (main column)
st.markdown("""
### ğŸ’¬ Submit a Prompt
_Type a question or statement your LLM might generate. This demo simulates evaluation for reliability, compliance, and reasoning beneath models like GPT-4, Claude, or Gemini._
""")
# Note: Using the same user_prompt from sidebar to avoid duplicate inputs
if user_prompt:
    # Simulated dynamic reliability score (fake, IP-safe)
    keywords = ["compliant", "data", "model"]
    trust_score = min(95, 80 + sum(word in user_prompt.lower() for word in keywords) * 5 + len(user_prompt.split()) % 11)
    compliance_results = {
        "EU AI Act": "âœ… Fully Compliant",
        "GDPR": "âš ï¸ Partial Compliance â€” Consent Clause Missing",
        "HIPAA": "âœ… No Violation Detected"
    }
    risk_level = "Moderate Risk" if "âš ï¸" in compliance_results.values() else "Low Risk"

    st.markdown("---")
    st.markdown("### âœ… Governance Analysis")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Reliability Score", f"{trust_score}% Reliable")
    with col2:
        st.warning(f"Risk Level: {risk_level}")

    st.markdown("#### ğŸ§¾ Compliance Checks")
    with st.expander("View Compliance Details"):
        for law, result in compliance_results.items():
            st.markdown(f"**{law}**: {result}")
            if "âš ï¸" in result:
                st.markdown(f"- *Reason*: Simulated gap in policy adherence.")
            else:
                st.markdown(f"- *Reason*: Passes simulated regulatory evaluation.")

    st.markdown("---")
    st.markdown("### ğŸ”— Symbolic Reasoning Trace (Interactive Graph)")
    
    # Enhanced graph using JSON
    G = nx.DiGraph()
    for rel in ontology_data["relations"]:
        G.add_edge(rel["source"], rel["target"], label=rel["type"])
    # Add demo-specific edges (still generic)
    G.add_edge("Prompt", "Data Input", label="processed by")
    G.add_edge("Data Input", "Sentiment Model", label="feeds")
    G.add_edge("Sentiment Model", "Compliance", label="evaluated by")
    G.add_edge("Compliance", "EU AI Act", label="checks")
    G.add_edge("EU AI Act", "âœ” Compliant", label="passes")
    G.add_edge("Compliance", "HIPAA", label="checks")
    G.add_edge("HIPAA", "âœ” Compliant", label="passes")

    # Cluster-based node coloring
    cluster_colors = {
        "AI Ethics": "green",
        "Model Governance": "blue",
        "Regulatory Risk": "orange",
        "Transparency & Explainability": "purple",
        "Data Protection": "red"
    }
    # Map concepts to clusters
    concept_to_cluster = {c["label"]: c["cluster"] for c in ontology_data["concepts"]}
    # Assign colors to nodes, defaulting to lightblue for demo-specific nodes
    node_colors = [cluster_colors.get(concept_to_cluster.get(node, ""), "lightblue") for node in G.nodes()]

    pos = nx.spring_layout(G, seed=42)
    edge_labels = nx.get_edge_attributes(G, 'label')
    fig, ax = plt.subplots(figsize=(12, 8))
    nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=3000, font_size=12, arrows=True, edge_color='gray', ax=ax)
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)
    plt.title("Symbolic Reasoning Preview")
    st.pyplot(fig)

    # Cluster Legend
    st.markdown("### ğŸ—ºï¸ Cluster Legend")
    st.markdown("ğŸŸ¢ AI Ethics â€¢ ğŸ”µ Model Governance â€¢ ğŸŸ  Regulatory Risk â€¢ ğŸŸ£ Transparency & Explainability â€¢ ğŸ”´ Data Protection")

    # Reasoning Paths
    st.markdown("### ğŸ›¤ï¸ Reasoning Paths")
    reasoning_paths = [
        "Prompt â†’ Compliance â†’ GDPR â†’ Regulatory Fine",
        "Prompt â†’ Machine Learning â†’ Model Bias â†’ Fairness"
    ]
    for path in reasoning_paths:
        st.markdown(f"- **Path**: {path}")
    st.markdown("_These paths trace how prompts connect to impacts through the ontology._")

    st.markdown("""
    _This graph previews how an OntoGuard-inspired layer symbolically connects concepts to govern LLM reliability and compliance._
    """)

st.markdown("---")
st.markdown("""
#### ğŸ‘¤ Invented & Built by Mark Starobinsky
- ğŸ“œ Featured in Marquis Who's Who 2025
- ğŸ“© [Contact via LinkedIn](https://www.linkedin.com/in/markstarobinsky)

_This redacted demo excludes proprietary drift detection, federated validation, and sub-second reasoningâ€”unlock the full OntoGuard platform under NDA._
""")
if st.button("Request NDA Details"):
    st.markdown("ğŸ“§ Please contact [markstarobinsky@yourdomain.com](mailto:markstarobinsky@yourdomain.com) to initiate NDA discussions.")